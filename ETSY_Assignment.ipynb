{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lD-NyMuv_ZSS",
        "outputId": "ac02e762-74a9-43b7-b657-b984c310cc29"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "#importing required libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import metrics\n",
        "import glob\n",
        "import pyarrow.parquet as pq\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('wordnet')\n",
        "import math\n",
        "import re\n",
        "import string\n",
        "import pyarrow as pa\n",
        "import os\n",
        "import math\n",
        "import seaborn as sb\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "#!unzip /content/gdrive/MyDrive/data.zip -d /content/gdrive/MyDrive/Etsy_Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b-nQUCTx_gAD"
      },
      "outputs": [],
      "source": [
        "#setting path and loading the csv file\n",
        "PATH = f\"/content/gdrive/MyDrive/Etsy_Data/data\"\n",
        "p_f = f'{PATH}/parquet/train'\n",
        "test = pd.read_parquet(p_f,engine='pyarrow')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1onjzKRDREA-",
        "outputId": "f853a31e-457b-48b9-c2c8-205b15a63381"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['product_id', 'title', 'description', 'tags', 'type', 'room',\n",
              "       'craft_type', 'recipient', 'material', 'occasion', 'holiday',\n",
              "       'art_subject', 'style', 'shape', 'pattern', 'bottom_category_id',\n",
              "       'bottom_category_text', 'top_category_id', 'top_category_text',\n",
              "       'color_id', 'color_text'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E_SMYDO7TwBa",
        "outputId": "94e51374-e9b3-4be0-a90c-436fe1077fbf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 245485 entries, 0 to 245484\n",
            "Data columns (total 21 columns):\n",
            " #   Column                Non-Null Count   Dtype \n",
            "---  ------                --------------   ----- \n",
            " 0   product_id            245485 non-null  int64 \n",
            " 1   title                 244545 non-null  object\n",
            " 2   description           244545 non-null  object\n",
            " 3   tags                  210575 non-null  object\n",
            " 4   type                  244211 non-null  object\n",
            " 5   room                  8727 non-null    object\n",
            " 6   craft_type            32520 non-null   object\n",
            " 7   recipient             13753 non-null   object\n",
            " 8   material              20876 non-null   object\n",
            " 9   occasion              53229 non-null   object\n",
            " 10  holiday               41019 non-null   object\n",
            " 11  art_subject           2773 non-null    object\n",
            " 12  style                 17032 non-null   object\n",
            " 13  shape                 2358 non-null    object\n",
            " 14  pattern               10678 non-null   object\n",
            " 15  bottom_category_id    245485 non-null  int64 \n",
            " 16  bottom_category_text  245485 non-null  object\n",
            " 17  top_category_id       245485 non-null  int64 \n",
            " 18  top_category_text     245485 non-null  object\n",
            " 19  color_id              245485 non-null  int64 \n",
            " 20  color_text            245485 non-null  object\n",
            "dtypes: int64(4), object(17)\n",
            "memory usage: 39.3+ MB\n"
          ]
        }
      ],
      "source": [
        "test.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4rDpSxvWnmqm"
      },
      "source": [
        "## Dropping unnecessary columns\n",
        "Removed the columns such as tags, type, room etc since there were more than 50% missing values which were not imputable and columns were of no use.\n",
        "Also removed the type column since it is not giving to much information for the analysis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "88vJCREETzaC"
      },
      "outputs": [],
      "source": [
        "#Dropping the columns which are not required\n",
        "test = test.drop(['type', 'room',\n",
        "       'craft_type', 'recipient', 'material', 'occasion', 'holiday',\n",
        "       'art_subject', 'style', 'shape', 'pattern'],axis = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8jlez7dDT1qz",
        "outputId": "e764a50b-810f-4220-f7fe-de522724305c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 245485 entries, 0 to 245484\n",
            "Data columns (total 10 columns):\n",
            " #   Column                Non-Null Count   Dtype \n",
            "---  ------                --------------   ----- \n",
            " 0   product_id            245485 non-null  int64 \n",
            " 1   title                 244545 non-null  object\n",
            " 2   description           244545 non-null  object\n",
            " 3   tags                  210575 non-null  object\n",
            " 4   bottom_category_id    245485 non-null  int64 \n",
            " 5   bottom_category_text  245485 non-null  object\n",
            " 6   top_category_id       245485 non-null  int64 \n",
            " 7   top_category_text     245485 non-null  object\n",
            " 8   color_id              245485 non-null  int64 \n",
            " 9   color_text            245485 non-null  object\n",
            "dtypes: int64(4), object(6)\n",
            "memory usage: 18.7+ MB\n"
          ]
        }
      ],
      "source": [
        "test.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WkKG4E9XG2LE"
      },
      "source": [
        "### Basic Cleaning of Text Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SFY_SkZeBMqW",
        "outputId": "81acb7e4-778c-4339-9b1e-4b36634a1c5a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-17-e350f8db3654>:3: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  test['title'] = test['title'].str.replace(r'\\\\n','')\n",
            "<ipython-input-17-e350f8db3654>:4: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  test['title'] = test['title'].str.replace('[^A-Za-z\\s]','')\n",
            "<ipython-input-17-e350f8db3654>:5: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  test['title'] = test['title'].str.replace('\\d+','')\n",
            "<ipython-input-17-e350f8db3654>:6: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  test['title'] = test['title'].str.replace(r'http\\S+|www.\\S+', '')\n",
            "<ipython-input-17-e350f8db3654>:10: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  test['description'] = test['description'].str.replace(r'\\\\n','')\n",
            "<ipython-input-17-e350f8db3654>:11: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  test['description'] = test['description'].str.replace('[^A-Za-z\\s]','')\n",
            "<ipython-input-17-e350f8db3654>:12: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  test['description'] = test['description'].str.replace('\\d+','')\n",
            "<ipython-input-17-e350f8db3654>:13: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  test['description'] = test['description'].str.replace(r'http\\S+|www.\\S+', '')\n",
            "<ipython-input-17-e350f8db3654>:17: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  test['tags'] = test['tags'].str.replace(r'\\\\n','')\n",
            "<ipython-input-17-e350f8db3654>:18: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  test['tags'] = test['tags'].str.replace('[^A-Za-z\\s]','')\n",
            "<ipython-input-17-e350f8db3654>:19: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  test['tags'] = test['tags'].str.replace('\\d+','')\n",
            "<ipython-input-17-e350f8db3654>:20: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  test['tags'] = test['tags'].str.replace(r'http\\S+|www.\\S+', '')\n"
          ]
        }
      ],
      "source": [
        "test['title'] = test['title'].fillna(\"\")\n",
        "test['title'] = test['title'].apply(lambda x: x.lower() if pd.notna(x) else x)\n",
        "test['title'] = test['title'].str.replace(r'\\\\n','')\n",
        "test['title'] = test['title'].str.replace('[^A-Za-z\\s]','')\n",
        "test['title'] = test['title'].str.replace('\\d+','')\n",
        "test['title'] = test['title'].str.replace(r'http\\S+|www.\\S+', '')\n",
        "\n",
        "test['description'] = test['description'].fillna(\"\")\n",
        "test['description'] = test['description'].apply(lambda x: x.lower() if pd.notna(x) else x)\n",
        "test['description'] = test['description'].str.replace(r'\\\\n','')\n",
        "test['description'] = test['description'].str.replace('[^A-Za-z\\s]','')\n",
        "test['description'] = test['description'].str.replace('\\d+','')\n",
        "test['description'] = test['description'].str.replace(r'http\\S+|www.\\S+', '')\n",
        "\n",
        "test['tags'] = test['tags'].fillna(\"\")\n",
        "test['tags'] = test['tags'].apply(lambda x: x.lower() if pd.notna(x) else x)\n",
        "test['tags'] = test['tags'].str.replace(r'\\\\n','')\n",
        "test['tags'] = test['tags'].str.replace('[^A-Za-z\\s]','')\n",
        "test['tags'] = test['tags'].str.replace('\\d+','')\n",
        "test['tags'] = test['tags'].str.replace(r'http\\S+|www.\\S+', '')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4mry68UyGuhE"
      },
      "source": [
        "### Remove Stop Words from the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l_3_g7lfBL87",
        "outputId": "fc6d2104-5fce-4693-97cb-804f9deafcf5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "nltk.download('stopwords')\n",
        "stop_words = stopwords.words('english')\n",
        "def remove_stop_words(text):\n",
        "    if pd.isna(text):\n",
        "        return ''\n",
        "    words = text.split()\n",
        "    filtered_words = [word for word in words if len(word) > 2 and word not in stop_words]\n",
        "    return ' '.join(filtered_words)\n",
        "\n",
        "test['title'] = test['title'].apply(remove_stop_words)\n",
        "test['description'] = test['description'].apply(remove_stop_words)\n",
        "test['tags'] = test['tags'].apply(remove_stop_words)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ETvj4p8CHAos"
      },
      "source": [
        "### Lemmatise the Text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8W5A-Es_BLui"
      },
      "outputs": [],
      "source": [
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def wordnet_pos(tag):\n",
        "        if tag.startswith('J'):\n",
        "            return wordnet.ADJ\n",
        "        elif tag.startswith('R'):\n",
        "            return wordnet.ADV\n",
        "        elif tag.startswith('V'):\n",
        "            return wordnet.VERB\n",
        "        elif tag.startswith('N'):\n",
        "            return wordnet.NOUN\n",
        "        else:\n",
        "            return wordnet.NOUN\n",
        "\n",
        "def lemmatization_of_text(text):\n",
        "    words = word_tokenize(text)\n",
        "    pos_tags = nltk.pos_tag(words)\n",
        "    lemmatized_words = [lemmatizer.lemmatize(word, wordnet_pos(tag)) for word, tag in pos_tags]\n",
        "    lemmatized_text = ' '.join(lemmatized_words)\n",
        "    return lemmatized_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ho3c7AcUBLgJ"
      },
      "outputs": [],
      "source": [
        "test['description']=test['description'].apply(lemmatization_of_text)\n",
        "test['title']=test['title'].apply(lemmatization_of_text)\n",
        "test['tags']=test['tags'].apply(lemmatization_of_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vsJekoT0BLMB"
      },
      "outputs": [],
      "source": [
        "test['combine'] = test['title'] + ' ' + test['description'] + ' ' + test['tags']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "EfaIhGeLUXLs",
        "outputId": "c16e4bc0-d73d-47c4-8d4c-5cdbea5d5ec1"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-cfa9a89a-50fc-48d9-aab5-543f2ca6f5c5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>product_id</th>\n",
              "      <th>title</th>\n",
              "      <th>description</th>\n",
              "      <th>tags</th>\n",
              "      <th>bottom_category_id</th>\n",
              "      <th>bottom_category_text</th>\n",
              "      <th>top_category_id</th>\n",
              "      <th>top_category_text</th>\n",
              "      <th>color_id</th>\n",
              "      <th>color_text</th>\n",
              "      <th>combine</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>543497833</td>\n",
              "      <td>fullface custom motorcycle helmet motorcycle s...</td>\n",
              "      <td>helmetartthai thailand since name phayong khon...</td>\n",
              "      <td>predator helmetmotorcycle helmethelmethandmade...</td>\n",
              "      <td>2804</td>\n",
              "      <td>accessories.hats_and_caps.helmets.sports_helme...</td>\n",
              "      <td>0</td>\n",
              "      <td>accessories</td>\n",
              "      <td>12</td>\n",
              "      <td>purple</td>\n",
              "      <td>fullface custom motorcycle helmet motorcycle s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>718680498</td>\n",
              "      <td>fullface predator motorcycle helmet custom pre...</td>\n",
              "      <td>helmetartthai thailand since name phayong khon...</td>\n",
              "      <td>predator helmetcustom helmethandmade helmepain...</td>\n",
              "      <td>2804</td>\n",
              "      <td>accessories.hats_and_caps.helmets.sports_helme...</td>\n",
              "      <td>0</td>\n",
              "      <td>accessories</td>\n",
              "      <td>1</td>\n",
              "      <td>black</td>\n",
              "      <td>fullface predator motorcycle helmet custom pre...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>718823736</td>\n",
              "      <td>fullface custom motorcycle helmet motorcycle s...</td>\n",
              "      <td>helmetartthai thailand since name phayong khon...</td>\n",
              "      <td>predator helmetcustom helmethandmade helmetair...</td>\n",
              "      <td>2804</td>\n",
              "      <td>accessories.hats_and_caps.helmets.sports_helme...</td>\n",
              "      <td>0</td>\n",
              "      <td>accessories</td>\n",
              "      <td>2</td>\n",
              "      <td>blue</td>\n",
              "      <td>fullface custom motorcycle helmet motorcycle s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>608840803</td>\n",
              "      <td>fullface custom motorcycle helmet motorcycle s...</td>\n",
              "      <td>helmetartthai thailand since name phayong khon...</td>\n",
              "      <td>predator helmetcustom helmethandmade helmethel...</td>\n",
              "      <td>2804</td>\n",
              "      <td>accessories.hats_and_caps.helmets.sports_helme...</td>\n",
              "      <td>0</td>\n",
              "      <td>accessories</td>\n",
              "      <td>4</td>\n",
              "      <td>brown</td>\n",
              "      <td>fullface custom motorcycle helmet motorcycle s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>804070543</td>\n",
              "      <td>fullface predator motorcycle helmet custom pre...</td>\n",
              "      <td>helmetartthai thailand since name phayong khon...</td>\n",
              "      <td>custom helmethandmade helmetpredator helmethel...</td>\n",
              "      <td>2804</td>\n",
              "      <td>accessories.hats_and_caps.helmets.sports_helme...</td>\n",
              "      <td>0</td>\n",
              "      <td>accessories</td>\n",
              "      <td>1</td>\n",
              "      <td>black</td>\n",
              "      <td>fullface predator motorcycle helmet custom pre...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>245480</th>\n",
              "      <td>1330991677</td>\n",
              "      <td>vintage apri night black alumesh evening bag c...</td>\n",
              "      <td>charm vintage apri night black alumesh evening...</td>\n",
              "      <td>black mesh beadingapri nightsevening bagcrossb...</td>\n",
              "      <td>157</td>\n",
              "      <td>bags_and_purses.handbags.clutches_and_evening_...</td>\n",
              "      <td>2</td>\n",
              "      <td>bags_and_purses</td>\n",
              "      <td>1</td>\n",
              "      <td>black</td>\n",
              "      <td>vintage apri night black alumesh evening bag c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>245481</th>\n",
              "      <td>927998323</td>\n",
              "      <td>gold eloquent envelope clutch bag</td>\n",
              "      <td>look classy posh bag hit hot club gold envelop...</td>\n",
              "      <td>clutchgoldsoftenvelopedisco</td>\n",
              "      <td>157</td>\n",
              "      <td>bags_and_purses.handbags.clutches_and_evening_...</td>\n",
              "      <td>2</td>\n",
              "      <td>bags_and_purses</td>\n",
              "      <td>7</td>\n",
              "      <td>gold</td>\n",
              "      <td>gold eloquent envelope clutch bag look classy ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>245482</th>\n",
              "      <td>1393052238</td>\n",
              "      <td>personalize pouch toiletry bag makeup bag</td>\n",
              "      <td>personalize item return exchange accordance ge...</td>\n",
              "      <td></td>\n",
              "      <td>157</td>\n",
              "      <td>bags_and_purses.handbags.clutches_and_evening_...</td>\n",
              "      <td>2</td>\n",
              "      <td>bags_and_purses</td>\n",
              "      <td>17</td>\n",
              "      <td>white</td>\n",
              "      <td>personalize pouch toiletry bag makeup bag pers...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>245483</th>\n",
              "      <td>775199837</td>\n",
              "      <td>floral handbag canvas bag bridesmaid bag guest...</td>\n",
              "      <td>handbag flower jute ideal day partiesdetails c...</td>\n",
              "      <td>flower handbagcanvas bagbridesmaid bagguest ba...</td>\n",
              "      <td>157</td>\n",
              "      <td>bags_and_purses.handbags.clutches_and_evening_...</td>\n",
              "      <td>2</td>\n",
              "      <td>bags_and_purses</td>\n",
              "      <td>0</td>\n",
              "      <td>beige</td>\n",
              "      <td>floral handbag canvas bag bridesmaid bag guest...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>245484</th>\n",
              "      <td>1136519781</td>\n",
              "      <td>modern marrakesh bohemian seed bead clutch bag...</td>\n",
              "      <td>modern marrakesh bohemian seed bead clutch bag...</td>\n",
              "      <td>bead clutchseed bead bagsbeaded bagsbead clutc...</td>\n",
              "      <td>157</td>\n",
              "      <td>bags_and_purses.handbags.clutches_and_evening_...</td>\n",
              "      <td>2</td>\n",
              "      <td>bags_and_purses</td>\n",
              "      <td>13</td>\n",
              "      <td>rainbow</td>\n",
              "      <td>modern marrakesh bohemian seed bead clutch bag...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>245485 rows Ã— 11 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cfa9a89a-50fc-48d9-aab5-543f2ca6f5c5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-cfa9a89a-50fc-48d9-aab5-543f2ca6f5c5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-cfa9a89a-50fc-48d9-aab5-543f2ca6f5c5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "        product_id                                              title  \\\n",
              "0        543497833  fullface custom motorcycle helmet motorcycle s...   \n",
              "1        718680498  fullface predator motorcycle helmet custom pre...   \n",
              "2        718823736  fullface custom motorcycle helmet motorcycle s...   \n",
              "3        608840803  fullface custom motorcycle helmet motorcycle s...   \n",
              "4        804070543  fullface predator motorcycle helmet custom pre...   \n",
              "...            ...                                                ...   \n",
              "245480  1330991677  vintage apri night black alumesh evening bag c...   \n",
              "245481   927998323                  gold eloquent envelope clutch bag   \n",
              "245482  1393052238          personalize pouch toiletry bag makeup bag   \n",
              "245483   775199837  floral handbag canvas bag bridesmaid bag guest...   \n",
              "245484  1136519781  modern marrakesh bohemian seed bead clutch bag...   \n",
              "\n",
              "                                              description  \\\n",
              "0       helmetartthai thailand since name phayong khon...   \n",
              "1       helmetartthai thailand since name phayong khon...   \n",
              "2       helmetartthai thailand since name phayong khon...   \n",
              "3       helmetartthai thailand since name phayong khon...   \n",
              "4       helmetartthai thailand since name phayong khon...   \n",
              "...                                                   ...   \n",
              "245480  charm vintage apri night black alumesh evening...   \n",
              "245481  look classy posh bag hit hot club gold envelop...   \n",
              "245482  personalize item return exchange accordance ge...   \n",
              "245483  handbag flower jute ideal day partiesdetails c...   \n",
              "245484  modern marrakesh bohemian seed bead clutch bag...   \n",
              "\n",
              "                                                     tags  bottom_category_id  \\\n",
              "0       predator helmetmotorcycle helmethelmethandmade...                2804   \n",
              "1       predator helmetcustom helmethandmade helmepain...                2804   \n",
              "2       predator helmetcustom helmethandmade helmetair...                2804   \n",
              "3       predator helmetcustom helmethandmade helmethel...                2804   \n",
              "4       custom helmethandmade helmetpredator helmethel...                2804   \n",
              "...                                                   ...                 ...   \n",
              "245480  black mesh beadingapri nightsevening bagcrossb...                 157   \n",
              "245481                        clutchgoldsoftenvelopedisco                 157   \n",
              "245482                                                                    157   \n",
              "245483  flower handbagcanvas bagbridesmaid bagguest ba...                 157   \n",
              "245484  bead clutchseed bead bagsbeaded bagsbead clutc...                 157   \n",
              "\n",
              "                                     bottom_category_text  top_category_id  \\\n",
              "0       accessories.hats_and_caps.helmets.sports_helme...                0   \n",
              "1       accessories.hats_and_caps.helmets.sports_helme...                0   \n",
              "2       accessories.hats_and_caps.helmets.sports_helme...                0   \n",
              "3       accessories.hats_and_caps.helmets.sports_helme...                0   \n",
              "4       accessories.hats_and_caps.helmets.sports_helme...                0   \n",
              "...                                                   ...              ...   \n",
              "245480  bags_and_purses.handbags.clutches_and_evening_...                2   \n",
              "245481  bags_and_purses.handbags.clutches_and_evening_...                2   \n",
              "245482  bags_and_purses.handbags.clutches_and_evening_...                2   \n",
              "245483  bags_and_purses.handbags.clutches_and_evening_...                2   \n",
              "245484  bags_and_purses.handbags.clutches_and_evening_...                2   \n",
              "\n",
              "       top_category_text  color_id color_text  \\\n",
              "0            accessories        12     purple   \n",
              "1            accessories         1      black   \n",
              "2            accessories         2       blue   \n",
              "3            accessories         4      brown   \n",
              "4            accessories         1      black   \n",
              "...                  ...       ...        ...   \n",
              "245480   bags_and_purses         1      black   \n",
              "245481   bags_and_purses         7       gold   \n",
              "245482   bags_and_purses        17      white   \n",
              "245483   bags_and_purses         0      beige   \n",
              "245484   bags_and_purses        13    rainbow   \n",
              "\n",
              "                                                  combine  \n",
              "0       fullface custom motorcycle helmet motorcycle s...  \n",
              "1       fullface predator motorcycle helmet custom pre...  \n",
              "2       fullface custom motorcycle helmet motorcycle s...  \n",
              "3       fullface custom motorcycle helmet motorcycle s...  \n",
              "4       fullface predator motorcycle helmet custom pre...  \n",
              "...                                                   ...  \n",
              "245480  vintage apri night black alumesh evening bag c...  \n",
              "245481  gold eloquent envelope clutch bag look classy ...  \n",
              "245482  personalize pouch toiletry bag makeup bag pers...  \n",
              "245483  floral handbag canvas bag bridesmaid bag guest...  \n",
              "245484  modern marrakesh bohemian seed bead clutch bag...  \n",
              "\n",
              "[245485 rows x 11 columns]"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Swf-H5-TfmHd"
      },
      "source": [
        "Converted the dataframe into csv file and stored it on Drive for easy usage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-gQohoGHA3Jn"
      },
      "outputs": [],
      "source": [
        "test.to_csv(r'/content/gdrive/MyDrive/Etsy_Data/Clean_text_data.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qPAylCgt4Usn"
      },
      "outputs": [],
      "source": [
        "test = pd.read_csv('/content/gdrive/MyDrive/Etsy_Data/Clean_text_data.csv')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test['bottom_category_id']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OVqpOsEGiEY5",
        "outputId": "ac5ba5e8-c6ec-40ce-83e7-e7c21e26f2ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 2804,  1406,  1515, ..., 11222, 12140,   157])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WqLq13avAoFO",
        "outputId": "e1b2000e-7d8d-43ed-a436-1fa50d7938ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 245485 entries, 0 to 245484\n",
            "Data columns (total 11 columns):\n",
            " #   Column                Non-Null Count   Dtype \n",
            "---  ------                --------------   ----- \n",
            " 0   product_id            245485 non-null  int64 \n",
            " 1   title                 244493 non-null  object\n",
            " 2   description           244496 non-null  object\n",
            " 3   tags                  210536 non-null  object\n",
            " 4   bottom_category_id    245485 non-null  int64 \n",
            " 5   bottom_category_text  245485 non-null  object\n",
            " 6   top_category_id       245485 non-null  int64 \n",
            " 7   top_category_text     245485 non-null  object\n",
            " 8   color_id              245485 non-null  int64 \n",
            " 9   color_text            245485 non-null  object\n",
            " 10  combine               245485 non-null  object\n",
            "dtypes: int64(4), object(7)\n",
            "memory usage: 20.6+ MB\n"
          ]
        }
      ],
      "source": [
        "test.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6m4ofk-ANLK8"
      },
      "source": [
        "## Models for top category prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CMW54uEgUZUc",
        "outputId": "d497e5ef-9a4d-4864-ca19-f44d046c8bce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top Category - Recall: 0.9966, F1 Score: 0.9966, Accuracy: 0.9966\n",
            "Val Top Category - Recall: 0.8948, F1 Score: 0.8945, Accuracy: 0.8948\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score,accuracy_score\n",
        "\n",
        "batch_size = 20000\n",
        "num_batches = len(test) // batch_size + (len(test) % batch_size > 0)\n",
        "model_top = LogisticRegression(max_iter=1000)\n",
        "\n",
        "vectorizer = CountVectorizer(max_features=10000)\n",
        "y_true_train = []\n",
        "y_pred_train = []\n",
        "y_true_val = []\n",
        "y_pred_val = []\n",
        "\n",
        "for i in range(num_batches):\n",
        "    start_idx = i * batch_size\n",
        "    end_idx = min(start_idx + batch_size, len(test))\n",
        "    X_text = test['combine'][start_idx:end_idx]\n",
        "    y = test['top_category_id'][start_idx:end_idx]\n",
        "\n",
        "    X = vectorizer.fit_transform(X_text)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    model_top.fit(X_train,y_train)\n",
        "\n",
        "    y_pred_train_batch = model_top.predict(X_train)\n",
        "    y_true_train.extend(y_train)\n",
        "    y_pred_train.extend(y_pred_train_batch)\n",
        "\n",
        "    y_pred_val_batch = model_top.predict(X_test)\n",
        "    y_true_val.extend(y_test)\n",
        "    y_pred_val.extend(y_pred_val_batch)\n",
        "\n",
        "    train_recall = recall_score(y_true_train, y_pred_train, average='weighted')\n",
        "    train_f1_score = f1_score(y_true_train, y_pred_train, average='weighted')\n",
        "    train_accuracy = accuracy_score(y_true_train, y_pred_train)\n",
        "\n",
        "    val_recall = recall_score(y_true_val, y_pred_val, average='weighted')\n",
        "    val_f1_score = f1_score(y_true_val, y_pred_val, average='weighted')\n",
        "    val_accuracy = accuracy_score(y_true_val, y_pred_val)\n",
        "\n",
        "print(\"Top Category - Recall: {:.4f}, F1 Score: {:.4f}, Accuracy: {:.4f}\".format(train_recall, train_f1_score, train_accuracy))\n",
        "print(\"Val Top Category - Recall: {:.4f}, F1 Score: {:.4f}, Accuracy: {:.4f}\".format(val_recall, val_f1_score, val_accuracy))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zfd9g8eJcff6",
        "outputId": "2c73cee3-5980-4869-c6e5-1618d2e38949"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top Category - Recall: 0.9031, F1 Score: 0.9031, Accuracy: 0.9031\n",
            "Val Top Category - Recall: 0.8622, F1 Score: 0.8622, Accuracy: 0.8622\n"
          ]
        }
      ],
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score,accuracy_score\n",
        "\n",
        "batch_size = 20000\n",
        "num_batches = len(test) // batch_size + (len(test) % batch_size > 0)\n",
        "model = MultinomialNB()\n",
        "\n",
        "vectorizer = CountVectorizer(max_features=10000)\n",
        "y_true_train = []\n",
        "y_pred_train = []\n",
        "y_true_val = []\n",
        "y_pred_val = []\n",
        "\n",
        "for i in range(num_batches):\n",
        "    start_idx = i * batch_size\n",
        "    end_idx = min(start_idx + batch_size, len(test))\n",
        "    X_text = test['combine'][start_idx:end_idx]\n",
        "    y = test['top_category_id'][start_idx:end_idx]\n",
        "\n",
        "    X = vectorizer.fit_transform(X_text)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    model.fit(X_train,y_train)\n",
        "\n",
        "    y_pred_train_batch = model.predict(X_train)\n",
        "    y_true_train.extend(y_train)\n",
        "    y_pred_train.extend(y_pred_train_batch)\n",
        "\n",
        "    y_pred_val_batch = model.predict(X_test)\n",
        "    y_true_val.extend(y_test)\n",
        "    y_pred_val.extend(y_pred_val_batch)\n",
        "\n",
        "    train_recall = recall_score(y_true_train, y_pred_train, average='weighted')\n",
        "    train_f1_score = f1_score(y_true_train, y_pred_train, average='weighted')\n",
        "    train_accuracy = accuracy_score(y_true_train, y_pred_train)\n",
        "\n",
        "\n",
        "    val_recall = recall_score(y_true_val, y_pred_val, average='weighted')\n",
        "    val_f1_score = f1_score(y_true_val, y_pred_val, average='weighted')\n",
        "    val_accuracy = accuracy_score(y_true_val, y_pred_val)\n",
        "\n",
        "print(\"Top Category - Recall: {:.4f}, F1 Score: {:.4f}, Accuracy: {:.4f}\".format(train_recall, train_f1_score, train_accuracy))\n",
        "print(\"Val Top Category - Recall: {:.4f}, F1 Score: {:.4f}, Accuracy: {:.4f}\".format(val_recall, val_f1_score, val_accuracy))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lx8NZZ5k108-",
        "outputId": "09afa933-9ff7-4d51-b0db-4f18cdfa403b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top Category - Recall: 0.9310, F1 Score: 0.9309, Accuracy: 0.9310\n",
            "Val Top Category - Recall: 0.8394, F1 Score: 0.8386, Accuracy: 0.8394\n"
          ]
        }
      ],
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score\n",
        "\n",
        "batch_size = 20000\n",
        "num_batches = len(test) // batch_size + (len(test) % batch_size > 0)\n",
        "model = SVC()\n",
        "\n",
        "vectorizer = CountVectorizer()\n",
        "y_true_train = []\n",
        "y_pred_train = []\n",
        "y_true_val = []\n",
        "y_pred_val = []\n",
        "\n",
        "for i in range(num_batches):\n",
        "    start_idx = i * batch_size\n",
        "    end_idx = min(start_idx + batch_size, len(test))\n",
        "    X_text = test['combine'][start_idx:end_idx]\n",
        "    y = test['top_category_id'][start_idx:end_idx]\n",
        "\n",
        "    X = vectorizer.fit_transform(X_text)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    model.fit(X_train,y_train)\n",
        "\n",
        "    y_pred_train_batch = model.predict(X_train)\n",
        "    y_true_train.extend(y_train)\n",
        "    y_pred_train.extend(y_pred_train_batch)\n",
        "\n",
        "    y_pred_val_batch = model.predict(X_test)\n",
        "    y_true_val.extend(y_test)\n",
        "    y_pred_val.extend(y_pred_val_batch)\n",
        "\n",
        "    train_recall = recall_score(y_true_train, y_pred_train, average='weighted')\n",
        "    train_f1_score = f1_score(y_true_train, y_pred_train, average='weighted')\n",
        "    train_accuracy = accuracy_score(y_true_train, y_pred_train)\n",
        "\n",
        "    val_recall = recall_score(y_true_val, y_pred_val, average='weighted')\n",
        "    val_f1_score = f1_score(y_true_val, y_pred_val, average='weighted')\n",
        "    val_accuracy = accuracy_score(y_true_val, y_pred_val)\n",
        "\n",
        "print(\"Top Category - Recall: {:.4f}, F1 Score: {:.4f}, Accuracy: {:.4f}\".format(train_recall, train_f1_score, train_accuracy))\n",
        "print(\"Val Top Category - Recall: {:.4f}, F1 Score: {:.4f}, Accuracy: {:.4f}\".format(val_recall, val_f1_score, val_accuracy))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8XxmTfS_2GUd",
        "outputId": "b00fac08-5ff5-42d7-b4e8-14e71fa4ccf0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top Category - Recall: 0.9972, F1 Score: 0.9972, Accuracy: 0.9972\n",
            "Val Top Category - Recall: 0.7425, F1 Score: 0.7414, Accuracy: 0.7425\n"
          ]
        }
      ],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score\n",
        "\n",
        "batch_size = 20000\n",
        "num_batches = len(test) // batch_size + (len(test) % batch_size > 0)\n",
        "model = DecisionTreeClassifier(random_state=0)\n",
        "\n",
        "vectorizer = CountVectorizer()\n",
        "y_true_train = []\n",
        "y_pred_train = []\n",
        "y_true_val = []\n",
        "y_pred_val = []\n",
        "\n",
        "for i in range(num_batches):\n",
        "    start_idx = i * batch_size\n",
        "    end_idx = min(start_idx + batch_size, len(test))\n",
        "    X_text = test['combine'][start_idx:end_idx]\n",
        "    y = test['top_category_id'][start_idx:end_idx]\n",
        "\n",
        "    X = vectorizer.fit_transform(X_text)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    model.fit(X_train,y_train)\n",
        "\n",
        "    y_pred_train_batch = model.predict(X_train)\n",
        "    y_true_train.extend(y_train)\n",
        "    y_pred_train.extend(y_pred_train_batch)\n",
        "\n",
        "    y_pred_val_batch = model.predict(X_test)\n",
        "    y_true_val.extend(y_test)\n",
        "    y_pred_val.extend(y_pred_val_batch)\n",
        "\n",
        "    train_recall = recall_score(y_true_train, y_pred_train, average='weighted')\n",
        "    train_f1_score = f1_score(y_true_train, y_pred_train, average='weighted')\n",
        "    train_accuracy = accuracy_score(y_true_train, y_pred_train)\n",
        "\n",
        "    val_recall = recall_score(y_true_val, y_pred_val, average='weighted')\n",
        "    val_f1_score = f1_score(y_true_val, y_pred_val, average='weighted')\n",
        "    val_accuracy = accuracy_score(y_true_val, y_pred_val)\n",
        "\n",
        "print(\"Top Category - Recall: {:.4f}, F1 Score: {:.4f}, Accuracy: {:.4f}\".format(train_recall, train_f1_score, train_accuracy))\n",
        "print(\"Val Top Category - Recall: {:.4f}, F1 Score: {:.4f}, Accuracy: {:.4f}\".format(val_recall, val_f1_score, val_accuracy))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kALk9FXpNV8N"
      },
      "source": [
        "## Models for Bottom Category Prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pm-CvBD42IdI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 414
        },
        "outputId": "6c334d9f-0cfa-439a-a63a-d4183912df1a"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-b5caf85cbf44>\u001b[0m in \u001b[0;36m<cell line: 16>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mmodel_bottom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0my_pred_train_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_bottom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1289\u001b[0m             \u001b[0mn_threads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1291\u001b[0;31m         fold_coefs_ = Parallel(n_jobs=self.n_jobs, verbose=self.verbose, prefer=prefer)(\n\u001b[0m\u001b[1;32m   1292\u001b[0m             path_func(\n\u001b[1;32m   1293\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         )\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1083\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1085\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1086\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1087\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    899\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    900\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 901\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    902\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    903\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    595\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 597\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    598\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    289\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    289\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36m_logistic_regression_path\u001b[0;34m(X, y, pos_class, Cs, fit_intercept, max_iter, tol, verbose, solver, coef, class_weight, dual, penalty, intercept_scaling, multi_class, random_state, check_input, max_squared_sum, sample_weight, l1_ratio, n_threads)\u001b[0m\n\u001b[1;32m    522\u001b[0m                 \u001b[0mbeta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0ml1_ratio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 524\u001b[0;31m             w0, n_iter_i, warm_start_sag = sag_solver(\n\u001b[0m\u001b[1;32m    525\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    526\u001b[0m                 \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_sag.py\u001b[0m in \u001b[0;36msag_solver\u001b[0;34m(X, y, sample_weight, loss, alpha, beta, max_iter, tol, verbose, random_state, check_input, max_squared_sum, warm_start_mem, is_saga)\u001b[0m\n\u001b[1;32m    323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m     \u001b[0msag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msag64\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0msag32\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m     num_seen, n_iter_ = sag(\n\u001b[0m\u001b[1;32m    326\u001b[0m         \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m         \u001b[0mcoef_init\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score,accuracy_score\n",
        "\n",
        "batch_size = 15000\n",
        "num_batches = len(test) // batch_size + (len(test) % batch_size > 0)\n",
        "model_bottom = LogisticRegression(penalty='l1',solver='saga',max_iter=1000)\n",
        "\n",
        "vectorizer = CountVectorizer(max_features=10000)\n",
        "y_true_train = []\n",
        "y_pred_train = []\n",
        "y_true_val = []\n",
        "y_pred_val = []\n",
        "\n",
        "for i in range(num_batches):\n",
        "    start_idx = i * batch_size\n",
        "    end_idx = min(start_idx + batch_size, len(test))\n",
        "    X_text = test['combine'][start_idx:end_idx]\n",
        "    y = test['bottom_category_id'][start_idx:end_idx]\n",
        "\n",
        "    X = vectorizer.fit_transform(X_text)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    model_bottom.fit(X_train,y_train)\n",
        "\n",
        "    y_pred_train_batch = model_bottom.predict(X_train)\n",
        "    y_true_train.extend(y_train)\n",
        "    y_pred_train.extend(y_pred_train_batch)\n",
        "\n",
        "    y_pred_val_batch = model_bottom.predict(X_test)\n",
        "    y_true_val.extend(y_test)\n",
        "    y_pred_val.extend(y_pred_val_batch)\n",
        "\n",
        "    train_recall = recall_score(y_true_train, y_pred_train, average='weighted')\n",
        "    train_f1_score = f1_score(y_true_train, y_pred_train, average='weighted')\n",
        "    train_accuracy = accuracy_score(y_true_train, y_pred_train)\n",
        "\n",
        "    val_recall = recall_score(y_true_val, y_pred_val, average='weighted')\n",
        "    val_f1_score = f1_score(y_true_val, y_pred_val, average='weighted')\n",
        "    val_accuracy = accuracy_score(y_true_val, y_pred_val)\n",
        "\n",
        "print(\"Bottom Category - Recall: {:.4f}, F1 Score: {:.4f}, Accuracy: {:.4f}\".format(train_recall, train_f1_score, train_accuracy))\n",
        "print(\"Val Bottom Category - Recall: {:.4f}, F1 Score: {:.4f}, Accuracy: {:.4f}\".format(val_recall, val_f1_score, val_accuracy))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-nlyCD3z2s9n",
        "outputId": "99ab99bc-41de-4a43-92da-d720a9b8fc40"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top Category - Recall: 0.9408, F1 Score: 0.9429, Accuracy: 0.9408\n",
            "Val Top Category - Recall: 0.7379, F1 Score: 0.7456, Accuracy: 0.7379\n"
          ]
        }
      ],
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score,accuracy_score\n",
        "\n",
        "batch_size = 20000\n",
        "num_batches = len(test) // batch_size + (len(test) % batch_size > 0)\n",
        "model = MultinomialNB()\n",
        "\n",
        "vectorizer = CountVectorizer()\n",
        "y_true_train = []\n",
        "y_pred_train = []\n",
        "y_true_val = []\n",
        "y_pred_val = []\n",
        "\n",
        "for i in range(num_batches):\n",
        "    start_idx = i * batch_size\n",
        "    end_idx = min(start_idx + batch_size, len(test))\n",
        "    X_text = test['combine'][start_idx:end_idx]\n",
        "    y = test['bottom_category_id'][start_idx:end_idx]\n",
        "\n",
        "    X = vectorizer.fit_transform(X_text)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    model.fit(X_train,y_train)\n",
        "\n",
        "    y_pred_train_batch = model.predict(X_train)\n",
        "    y_true_train.extend(y_train)\n",
        "    y_pred_train.extend(y_pred_train_batch)\n",
        "\n",
        "    y_pred_val_batch = model.predict(X_test)\n",
        "    y_true_val.extend(y_test)\n",
        "    y_pred_val.extend(y_pred_val_batch)\n",
        "\n",
        "    train_recall = recall_score(y_true_train, y_pred_train, average='weighted')\n",
        "    train_f1_score = f1_score(y_true_train, y_pred_train, average='weighted')\n",
        "    train_accuracy = accuracy_score(y_true_train, y_pred_train)\n",
        "\n",
        "\n",
        "    val_recall = recall_score(y_true_val, y_pred_val, average='weighted')\n",
        "    val_f1_score = f1_score(y_true_val, y_pred_val, average='weighted')\n",
        "    val_accuracy = accuracy_score(y_true_val, y_pred_val)\n",
        "\n",
        "print(\"Top Category - Recall: {:.4f}, F1 Score: {:.4f}, Accuracy: {:.4f}\".format(train_recall, train_f1_score, train_accuracy))\n",
        "print(\"Val Top Category - Recall: {:.4f}, F1 Score: {:.4f}, Accuracy: {:.4f}\".format(val_recall, val_f1_score, val_accuracy))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1PJrSXUR2vbQ",
        "outputId": "74fd9a9f-abf8-48ff-be54-f84fcd7a9e1b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top Category - Recall: 0.8970, F1 Score: 0.9193, Accuracy: 0.8970\n",
            "Val Top Category - Recall: 0.7095, F1 Score: 0.7519, Accuracy: 0.7095\n"
          ]
        }
      ],
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score,accuracy_score\n",
        "\n",
        "batch_size = 20000\n",
        "num_batches = len(test) // batch_size + (len(test) % batch_size > 0)\n",
        "model = SVC()\n",
        "\n",
        "vectorizer = CountVectorizer()\n",
        "y_true_train = []\n",
        "y_pred_train = []\n",
        "y_true_val = []\n",
        "y_pred_val = []\n",
        "\n",
        "for i in range(num_batches):\n",
        "    start_idx = i * batch_size\n",
        "    end_idx = min(start_idx + batch_size, len(test))\n",
        "    X_text = test['combine'][start_idx:end_idx]\n",
        "    y = test['bottom_category_id'][start_idx:end_idx]\n",
        "\n",
        "    X = vectorizer.fit_transform(X_text)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    model.fit(X_train,y_train)\n",
        "\n",
        "    y_pred_train_batch = model.predict(X_train)\n",
        "    y_true_train.extend(y_train)\n",
        "    y_pred_train.extend(y_pred_train_batch)\n",
        "\n",
        "    y_pred_val_batch = model.predict(X_test)\n",
        "    y_true_val.extend(y_test)\n",
        "    y_pred_val.extend(y_pred_val_batch)\n",
        "\n",
        "    train_recall = recall_score(y_true_train, y_pred_train, average='weighted')\n",
        "    train_f1_score = f1_score(y_true_train, y_pred_train, average='weighted')\n",
        "    train_accuracy = accuracy_score(y_true_train, y_pred_train)\n",
        "\n",
        "    val_recall = recall_score(y_true_val, y_pred_val, average='weighted')\n",
        "    val_f1_score = f1_score(y_true_val, y_pred_val, average='weighted')\n",
        "    val_accuracy = accuracy_score(y_true_val, y_pred_val)\n",
        "\n",
        "print(\"Top Category - Recall: {:.4f}, F1 Score: {:.4f}, Accuracy: {:.4f}\".format(train_recall, train_f1_score, train_accuracy))\n",
        "print(\"Val Top Category - Recall: {:.4f}, F1 Score: {:.4f}, Accuracy: {:.4f}\".format(val_recall, val_f1_score, val_accuracy))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7c-kqdB9U_Kp",
        "outputId": "8506dcec-2842-4c59-ac5f-e2d22ca56cce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top Category - Recall: 0.9968, F1 Score: 0.9972, Accuracy: 0.9968\n",
            "Val Top Category - Recall: 0.6869, F1 Score: 0.6873, Accuracy: 0.6869\n"
          ]
        }
      ],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score,accuracy_score\n",
        "\n",
        "batch_size = 20000\n",
        "num_batches = len(test) // batch_size + (len(test) % batch_size > 0)\n",
        "model = DecisionTreeClassifier(random_state=0)\n",
        "\n",
        "vectorizer = CountVectorizer()\n",
        "y_true_train = []\n",
        "y_pred_train = []\n",
        "y_true_val = []\n",
        "y_pred_val = []\n",
        "\n",
        "for i in range(num_batches):\n",
        "    start_idx = i * batch_size\n",
        "    end_idx = min(start_idx + batch_size, len(test))\n",
        "    X_text = test['combine'][start_idx:end_idx]\n",
        "    y = test['bottom_category_id'][start_idx:end_idx]\n",
        "\n",
        "    X = vectorizer.fit_transform(X_text)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    model.fit(X_train,y_train)\n",
        "\n",
        "    y_pred_train_batch = model.predict(X_train)\n",
        "    y_true_train.extend(y_train)\n",
        "    y_pred_train.extend(y_pred_train_batch)\n",
        "\n",
        "    y_pred_val_batch = model.predict(X_test)\n",
        "    y_true_val.extend(y_test)\n",
        "    y_pred_val.extend(y_pred_val_batch)\n",
        "\n",
        "    train_recall = recall_score(y_true_train, y_pred_train, average='weighted')\n",
        "    train_f1_score = f1_score(y_true_train, y_pred_train, average='weighted')\n",
        "    train_accuracy = accuracy_score(y_true_train, y_pred_train)\n",
        "\n",
        "    val_recall = recall_score(y_true_val, y_pred_val, average='weighted')\n",
        "    val_f1_score = f1_score(y_true_val, y_pred_val, average='weighted')\n",
        "    val_accuracy = accuracy_score(y_true_val, y_pred_val)\n",
        "\n",
        "print(\"Top Category - Recall: {:.4f}, F1 Score: {:.4f}, Accuracy: {:.4f}\".format(train_recall, train_f1_score, train_accuracy))\n",
        "print(\"Val Top Category - Recall: {:.4f}, F1 Score: {:.4f}, Accuracy: {:.4f}\".format(val_recall, val_f1_score, val_accuracy))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YDpwNPubXOdB"
      },
      "source": [
        "## Model For Color Id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TlQAdCUL3o6m"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score,accuracy_score\n",
        "\n",
        "batch_size = 20000\n",
        "num_batches = len(test) // batch_size + (len(test) % batch_size > 0)\n",
        "model_color = LogisticRegression(max_iter=1000)\n",
        "\n",
        "vectorizer = CountVectorizer(max_features=10000)\n",
        "y_true_train = []\n",
        "y_pred_train = []\n",
        "y_true_val = []\n",
        "y_pred_val = []\n",
        "\n",
        "for i in range(num_batches):\n",
        "    start_idx = i * batch_size\n",
        "    end_idx = min(start_idx + batch_size, len(test))\n",
        "    X_text = test['combine'][start_idx:end_idx]\n",
        "    y = test['color_id'][start_idx:end_idx]\n",
        "\n",
        "    X = vectorizer.fit_transform(X_text)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    model_color.fit(X_train,y_train)\n",
        "\n",
        "    y_pred_train_batch = model_color.predict(X_train)\n",
        "    y_true_train.extend(y_train)\n",
        "    y_pred_train.extend(y_pred_train_batch)\n",
        "\n",
        "    y_pred_val_batch = model_color.predict(X_test)\n",
        "    y_true_val.extend(y_test)\n",
        "    y_pred_val.extend(y_pred_val_batch)\n",
        "\n",
        "    train_recall = recall_score(y_true_train, y_pred_train, average='weighted')\n",
        "    train_f1_score = f1_score(y_true_train, y_pred_train, average='weighted')\n",
        "    train_accuracy = accuracy_score(y_true_train, y_pred_train)\n",
        "\n",
        "    val_recall = recall_score(y_true_val, y_pred_val, average='weighted')\n",
        "    val_f1_score = f1_score(y_true_val, y_pred_val, average='weighted')\n",
        "    val_accuracy = accuracy_score(y_true_val, y_pred_val)\n",
        "\n",
        "print(\"Top Category - Recall: {:.4f}, F1 Score: {:.4f}, Accuracy: {:.4f}\".format(train_recall, train_f1_score, train_accuracy))\n",
        "print(\"Val Top Category - Recall: {:.4f}, F1 Score: {:.4f}, Accuracy: {:.4f}\".format(val_recall, val_f1_score, val_accuracy))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ftw0MNyUiRxd",
        "outputId": "d84ce310-b463-4bac-a766-453d1839a271"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top Category - Recall: 0.5858, F1 Score: 0.5457, Accuracy: 0.5858\n",
            "Val Top Category - Recall: 0.3426, F1 Score: 0.2976, Accuracy: 0.3426\n"
          ]
        }
      ],
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score,accuracy_score\n",
        "\n",
        "batch_size = 20000\n",
        "num_batches = len(test) // batch_size + (len(test) % batch_size > 0)\n",
        "model_color = MultinomialNB()\n",
        "\n",
        "vectorizer = CountVectorizer()\n",
        "y_true_train = []\n",
        "y_pred_train = []\n",
        "y_true_val = []\n",
        "y_pred_val = []\n",
        "\n",
        "for i in range(num_batches):\n",
        "    start_idx = i * batch_size\n",
        "    end_idx = min(start_idx + batch_size, len(test))\n",
        "    X_text = test['combine'][start_idx:end_idx]\n",
        "    y = test['color_id'][start_idx:end_idx]\n",
        "\n",
        "    X = vectorizer.fit_transform(X_text)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    model_color.fit(X_train,y_train)\n",
        "\n",
        "    y_pred_train_batch = model_color.predict(X_train)\n",
        "    y_true_train.extend(y_train)\n",
        "    y_pred_train.extend(y_pred_train_batch)\n",
        "\n",
        "    y_pred_val_batch = model_color.predict(X_test)\n",
        "    y_true_val.extend(y_test)\n",
        "    y_pred_val.extend(y_pred_val_batch)\n",
        "\n",
        "    train_recall = recall_score(y_true_train, y_pred_train, average='weighted')\n",
        "    train_f1_score = f1_score(y_true_train, y_pred_train, average='weighted')\n",
        "    train_accuracy = accuracy_score(y_true_train, y_pred_train)\n",
        "\n",
        "\n",
        "    val_recall = recall_score(y_true_val, y_pred_val, average='weighted')\n",
        "    val_f1_score = f1_score(y_true_val, y_pred_val, average='weighted')\n",
        "    val_accuracy = accuracy_score(y_true_val, y_pred_val)\n",
        "\n",
        "print(\"Top Category - Recall: {:.4f}, F1 Score: {:.4f}, Accuracy: {:.4f}\".format(train_recall, train_f1_score, train_accuracy))\n",
        "print(\"Val Top Category - Recall: {:.4f}, F1 Score: {:.4f}, Accuracy: {:.4f}\".format(val_recall, val_f1_score, val_accuracy))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qOnl9ARhIdTN",
        "outputId": "563a8e69-d993-4049-de00-c0882b09e5a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top Category - Recall: 0.7035, F1 Score: 0.6988, Accuracy: 0.7035\n",
            "Val Top Category - Recall: 0.4467, F1 Score: 0.4292, Accuracy: 0.4467\n"
          ]
        }
      ],
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score,accuracy_score\n",
        "\n",
        "batch_size = 20000\n",
        "num_batches = len(test) // batch_size + (len(test) % batch_size > 0)\n",
        "model = SVC()\n",
        "\n",
        "vectorizer = CountVectorizer()\n",
        "y_true_train = []\n",
        "y_pred_train = []\n",
        "y_true_val = []\n",
        "y_pred_val = []\n",
        "\n",
        "for i in range(num_batches):\n",
        "    start_idx = i * batch_size\n",
        "    end_idx = min(start_idx + batch_size, len(test))\n",
        "    X_text = test['combine'][start_idx:end_idx]\n",
        "    y = test['color_id'][start_idx:end_idx]\n",
        "\n",
        "    X = vectorizer.fit_transform(X_text)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    model.fit(X_train,y_train)\n",
        "\n",
        "    y_pred_train_batch = model.predict(X_train)\n",
        "    y_true_train.extend(y_train)\n",
        "    y_pred_train.extend(y_pred_train_batch)\n",
        "\n",
        "    y_pred_val_batch = model.predict(X_test)\n",
        "    y_true_val.extend(y_test)\n",
        "    y_pred_val.extend(y_pred_val_batch)\n",
        "\n",
        "    train_recall = recall_score(y_true_train, y_pred_train, average='weighted')\n",
        "    train_f1_score = f1_score(y_true_train, y_pred_train, average='weighted')\n",
        "    train_accuracy = accuracy_score(y_true_train, y_pred_train)\n",
        "\n",
        "    val_recall = recall_score(y_true_val, y_pred_val, average='weighted')\n",
        "    val_f1_score = f1_score(y_true_val, y_pred_val, average='weighted')\n",
        "    val_accuracy = accuracy_score(y_true_val, y_pred_val)\n",
        "\n",
        "print(\"Top Category - Recall: {:.4f}, F1 Score: {:.4f}, Accuracy: {:.4f}\".format(train_recall, train_f1_score, train_accuracy))\n",
        "print(\"Val Top Category - Recall: {:.4f}, F1 Score: {:.4f}, Accuracy: {:.4f}\".format(val_recall, val_f1_score, val_accuracy))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iq8CnAgCZkvX",
        "outputId": "801cf500-de62-4e7a-d59d-abfb182c3e13"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top Category - Recall: 0.9945, F1 Score: 0.9945, Accuracy: 0.9945\n",
            "Val Top Category - Recall: 0.4303, F1 Score: 0.4280, Accuracy: 0.4303\n"
          ]
        }
      ],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score,accuracy_score\n",
        "\n",
        "batch_size = 20000\n",
        "num_batches = len(test) // batch_size + (len(test) % batch_size > 0)\n",
        "model = DecisionTreeClassifier(random_state=0)\n",
        "\n",
        "vectorizer = CountVectorizer()\n",
        "y_true_train = []\n",
        "y_pred_train = []\n",
        "y_true_val = []\n",
        "y_pred_val = []\n",
        "\n",
        "for i in range(num_batches):\n",
        "    start_idx = i * batch_size\n",
        "    end_idx = min(start_idx + batch_size, len(test))\n",
        "    X_text = test['combine'][start_idx:end_idx]\n",
        "    y = test['color_id'][start_idx:end_idx]\n",
        "\n",
        "    X = vectorizer.fit_transform(X_text)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    model.fit(X_train,y_train)\n",
        "\n",
        "    y_pred_train_batch = model.predict(X_train)\n",
        "    y_true_train.extend(y_train)\n",
        "    y_pred_train.extend(y_pred_train_batch)\n",
        "\n",
        "    y_pred_val_batch = model.predict(X_test)\n",
        "    y_true_val.extend(y_test)\n",
        "    y_pred_val.extend(y_pred_val_batch)\n",
        "\n",
        "    train_recall = recall_score(y_true_train, y_pred_train, average='weighted')\n",
        "    train_f1_score = f1_score(y_true_train, y_pred_train, average='weighted')\n",
        "    train_accuracy = accuracy_score(y_true_train, y_pred_train)\n",
        "\n",
        "    val_recall = recall_score(y_true_val, y_pred_val, average='weighted')\n",
        "    val_f1_score = f1_score(y_true_val, y_pred_val, average='weighted')\n",
        "    val_accuracy = accuracy_score(y_true_val, y_pred_val)\n",
        "\n",
        "print(\"Top Category - Recall: {:.4f}, F1 Score: {:.4f}, Accuracy: {:.4f}\".format(train_recall, train_f1_score, train_accuracy))\n",
        "print(\"Val Top Category - Recall: {:.4f}, F1 Score: {:.4f}, Accuracy: {:.4f}\".format(val_recall, val_f1_score, val_accuracy))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing Set"
      ],
      "metadata": {
        "id": "PfXJYJ8es3Vp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tLtD0gx_v9yn"
      },
      "outputs": [],
      "source": [
        "#setting path and loading the csv file\n",
        "PATH = f\"/content/gdrive/MyDrive/Etsy_Data/data\"\n",
        "p_f = f'{PATH}/parquet/test'\n",
        "final = pd.read_parquet(p_f,engine='pyarrow')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WPcObgppz-W7",
        "outputId": "313cfab6-25e2-4b9a-daa5-2221c7f21b52"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 27119 entries, 0 to 27118\n",
            "Data columns (total 15 columns):\n",
            " #   Column       Non-Null Count  Dtype \n",
            "---  ------       --------------  ----- \n",
            " 0   product_id   27119 non-null  int64 \n",
            " 1   title        27008 non-null  object\n",
            " 2   description  27008 non-null  object\n",
            " 3   tags         23232 non-null  object\n",
            " 4   type         26975 non-null  object\n",
            " 5   room         958 non-null    object\n",
            " 6   craft_type   3606 non-null   object\n",
            " 7   recipient    1478 non-null   object\n",
            " 8   material     2341 non-null   object\n",
            " 9   occasion     5766 non-null   object\n",
            " 10  holiday      4546 non-null   object\n",
            " 11  art_subject  278 non-null    object\n",
            " 12  style        1878 non-null   object\n",
            " 13  shape        302 non-null    object\n",
            " 14  pattern      1170 non-null   object\n",
            "dtypes: int64(1), object(14)\n",
            "memory usage: 3.1+ MB\n"
          ]
        }
      ],
      "source": [
        "final.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1UyuesRG0H_4"
      },
      "outputs": [],
      "source": [
        "final = final.drop(['type', 'room',\n",
        "       'craft_type', 'recipient', 'material', 'occasion', 'holiday',\n",
        "       'art_subject', 'style', 'shape', 'pattern'],axis = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "otvKaJAxeHhI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57bece2c-3938-4e7d-f486-770655c16b10"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 27119 entries, 0 to 27118\n",
            "Data columns (total 4 columns):\n",
            " #   Column       Non-Null Count  Dtype \n",
            "---  ------       --------------  ----- \n",
            " 0   product_id   27119 non-null  int64 \n",
            " 1   title        27008 non-null  object\n",
            " 2   description  27008 non-null  object\n",
            " 3   tags         23232 non-null  object\n",
            "dtypes: int64(1), object(3)\n",
            "memory usage: 847.6+ KB\n"
          ]
        }
      ],
      "source": [
        "final.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "biIJcqKYp8A4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db73325c-69f4-4bd8-ddef-57cecd0eb3ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-4dbaf3847965>:3: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  final['title'] = final['title'].str.replace(r'\\\\n','')\n",
            "<ipython-input-9-4dbaf3847965>:4: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  final['title'] = final['title'].str.replace('[^A-Za-z\\s]','')\n",
            "<ipython-input-9-4dbaf3847965>:5: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  final['title'] = final['title'].str.replace('\\d+','')\n",
            "<ipython-input-9-4dbaf3847965>:6: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  final['title'] = final['title'].str.replace(r'http\\S+|www.\\S+', '')\n",
            "<ipython-input-9-4dbaf3847965>:10: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  final['description'] = final['description'].str.replace(r'\\\\n','')\n",
            "<ipython-input-9-4dbaf3847965>:11: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  final['description'] = final['description'].str.replace('[^A-Za-z\\s]','')\n",
            "<ipython-input-9-4dbaf3847965>:12: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  final['description'] = final['description'].str.replace('\\d+','')\n",
            "<ipython-input-9-4dbaf3847965>:13: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  final['description'] = final['description'].str.replace(r'http\\S+|www.\\S+', '')\n",
            "<ipython-input-9-4dbaf3847965>:17: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  final['tags'] = final['tags'].str.replace(r'\\\\n','')\n",
            "<ipython-input-9-4dbaf3847965>:18: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  final['tags'] = final['tags'].str.replace('[^A-Za-z\\s]','')\n",
            "<ipython-input-9-4dbaf3847965>:19: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  final['tags'] = final['tags'].str.replace('\\d+','')\n",
            "<ipython-input-9-4dbaf3847965>:20: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  final['tags'] = final['tags'].str.replace(r'http\\S+|www.\\S+', '')\n"
          ]
        }
      ],
      "source": [
        "final['title'] = final['title'].fillna(\"\")\n",
        "final['title'] = final['title'].apply(lambda x: x.lower() if pd.notna(x) else x)\n",
        "final['title'] = final['title'].str.replace(r'\\\\n','')\n",
        "final['title'] = final['title'].str.replace('[^A-Za-z\\s]','')\n",
        "final['title'] = final['title'].str.replace('\\d+','')\n",
        "final['title'] = final['title'].str.replace(r'http\\S+|www.\\S+', '')\n",
        "\n",
        "final['description'] = final['description'].fillna(\"\")\n",
        "final['description'] = final['description'].apply(lambda x: x.lower() if pd.notna(x) else x)\n",
        "final['description'] = final['description'].str.replace(r'\\\\n','')\n",
        "final['description'] = final['description'].str.replace('[^A-Za-z\\s]','')\n",
        "final['description'] = final['description'].str.replace('\\d+','')\n",
        "final['description'] = final['description'].str.replace(r'http\\S+|www.\\S+', '')\n",
        "\n",
        "final['tags'] = final['tags'].fillna(\"\")\n",
        "final['tags'] = final['tags'].apply(lambda x: x.lower() if pd.notna(x) else x)\n",
        "final['tags'] = final['tags'].str.replace(r'\\\\n','')\n",
        "final['tags'] = final['tags'].str.replace('[^A-Za-z\\s]','')\n",
        "final['tags'] = final['tags'].str.replace('\\d+','')\n",
        "final['tags'] = final['tags'].str.replace(r'http\\S+|www.\\S+', '')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DHlhZdJ0NYP0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ccbcbf06-7d1d-4b31-9827-8a7bd12ca33e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "nltk.download('stopwords')\n",
        "stop_words = stopwords.words('english')\n",
        "def remove_stop_words(text):\n",
        "    if pd.isna(text):\n",
        "        return ''\n",
        "    words = text.split()\n",
        "    filtered_words = [word for word in words if len(word) > 2 and word not in stop_words]\n",
        "    return ' '.join(filtered_words)\n",
        "\n",
        "final['title'] = final['title'].apply(remove_stop_words)\n",
        "final['description'] = final['description'].apply(remove_stop_words)\n",
        "final['tags'] = final['tags'].apply(remove_stop_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d7vm1dVVZhaN"
      },
      "outputs": [],
      "source": [
        "from nltk.corpus import wordnet\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def wordnet_pos(tag):\n",
        "        if tag.startswith('J'):\n",
        "            return wordnet.ADJ\n",
        "        elif tag.startswith('R'):\n",
        "            return wordnet.ADV\n",
        "        elif tag.startswith('V'):\n",
        "            return wordnet.VERB\n",
        "        elif tag.startswith('N'):\n",
        "            return wordnet.NOUN\n",
        "        else:\n",
        "            return wordnet.NOUN\n",
        "\n",
        "def lemmatization_of_text(text):\n",
        "    words = word_tokenize(text)\n",
        "    pos_tags = nltk.pos_tag(words)\n",
        "    lemmatized_words = [lemmatizer.lemmatize(word, wordnet_pos(tag)) for word, tag in pos_tags]\n",
        "    lemmatized_text = ' '.join(lemmatized_words)\n",
        "    return lemmatized_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_RBnta3pZ-0Q"
      },
      "outputs": [],
      "source": [
        "final['description']=final['description'].apply(lemmatization_of_text)\n",
        "final['title']=final['title'].apply(lemmatization_of_text)\n",
        "final['tags']=final['tags'].apply(lemmatization_of_text)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final['combine'] = final['title'] + ' ' + final['description'] + ' ' + final['tags']"
      ],
      "metadata": {
        "id": "lzhfQ5jAyFX8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 641
        },
        "id": "-9I7TiVjygW3",
        "outputId": "0bac8f31-929c-4884-db39-188c867f888c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       product_id                                              title  \\\n",
              "0      1323824090  small press reddishorange japanese maple leave...   \n",
              "1       544175230  christmas artificial leaf holiday decor glitte...   \n",
              "2       895779370         fresh holly leave count christmas greenery   \n",
              "3       641102090  christmas artificial greenery gold plant glitt...   \n",
              "4      1340603160   red crown thorn corona thai hybrid sale cut root   \n",
              "...           ...                                                ...   \n",
              "27114   809100810                         book thing george stimpson   \n",
              "27115  1358895140  vintage story sugar hawaii softcover book hawa...   \n",
              "27116  1366768240  francis king man rock vintage penguin book fir...   \n",
              "27117  1168372040  child abbey regina roche three volume one illu...   \n",
              "27118  1157860460  eliot silas marner george eliot macmillan comp...   \n",
              "\n",
              "                                             description  \\\n",
              "0      small press reddishorange japanese maple leave...   \n",
              "1      glitter fake leavesprice leaf leaf size quot q...   \n",
              "2      list include fresh holly leave freshly pick pi...   \n",
              "3      glitter pine stemsprice branchthe total height...   \n",
              "4                                          free shipping   \n",
              "...                                                  ...   \n",
              "27114  vintage book thousand thing george stimpson fi...   \n",
              "27115  story sugar hawaiipublished hawaiian sugar pla...   \n",
              "27116  man rock seventh novel francis king hail beryl...   \n",
              "27117  charm early victorian antique edition child ab...   \n",
              "27118  store pet smoke free environmentshipping optio...   \n",
              "\n",
              "                                                    tags  \\\n",
              "0      leavesartcraftspaper craftsfallsoapbookmarksre...   \n",
              "1      holiday decorglitter fake leavesfaux greeneryf...   \n",
              "2      lucky holly leaveschristmas greenerychristmas ...   \n",
              "3      glitter pine stemsholiday decorchristmas craft...   \n",
              "4                           cactus live plantcrown thorn   \n",
              "...                                                  ...   \n",
              "27114                                                      \n",
              "27115  vintagehawaiisugarhistoryhawaiianfirst edition...   \n",
              "27116  penguin book penguinbook lover gift classic bo...   \n",
              "27117  child abbeyregina maria rocheregina rochevicto...   \n",
              "27118  silas marnerantique silas marnergeorge eliotma...   \n",
              "\n",
              "                                                 combine  \n",
              "0      small press reddishorange japanese maple leave...  \n",
              "1      christmas artificial leaf holiday decor glitte...  \n",
              "2      fresh holly leave count christmas greenery lis...  \n",
              "3      christmas artificial greenery gold plant glitt...  \n",
              "4      red crown thorn corona thai hybrid sale cut ro...  \n",
              "...                                                  ...  \n",
              "27114  book thing george stimpson vintage book thousa...  \n",
              "27115  vintage story sugar hawaii softcover book hawa...  \n",
              "27116  francis king man rock vintage penguin book fir...  \n",
              "27117  child abbey regina roche three volume one illu...  \n",
              "27118  eliot silas marner george eliot macmillan comp...  \n",
              "\n",
              "[27119 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1fbe7c9d-41e0-4f96-a50a-24fd038ff86a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>product_id</th>\n",
              "      <th>title</th>\n",
              "      <th>description</th>\n",
              "      <th>tags</th>\n",
              "      <th>combine</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1323824090</td>\n",
              "      <td>small press reddishorange japanese maple leave...</td>\n",
              "      <td>small press reddishorange japanese maple leave...</td>\n",
              "      <td>leavesartcraftspaper craftsfallsoapbookmarksre...</td>\n",
              "      <td>small press reddishorange japanese maple leave...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>544175230</td>\n",
              "      <td>christmas artificial leaf holiday decor glitte...</td>\n",
              "      <td>glitter fake leavesprice leaf leaf size quot q...</td>\n",
              "      <td>holiday decorglitter fake leavesfaux greeneryf...</td>\n",
              "      <td>christmas artificial leaf holiday decor glitte...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>895779370</td>\n",
              "      <td>fresh holly leave count christmas greenery</td>\n",
              "      <td>list include fresh holly leave freshly pick pi...</td>\n",
              "      <td>lucky holly leaveschristmas greenerychristmas ...</td>\n",
              "      <td>fresh holly leave count christmas greenery lis...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>641102090</td>\n",
              "      <td>christmas artificial greenery gold plant glitt...</td>\n",
              "      <td>glitter pine stemsprice branchthe total height...</td>\n",
              "      <td>glitter pine stemsholiday decorchristmas craft...</td>\n",
              "      <td>christmas artificial greenery gold plant glitt...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1340603160</td>\n",
              "      <td>red crown thorn corona thai hybrid sale cut root</td>\n",
              "      <td>free shipping</td>\n",
              "      <td>cactus live plantcrown thorn</td>\n",
              "      <td>red crown thorn corona thai hybrid sale cut ro...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27114</th>\n",
              "      <td>809100810</td>\n",
              "      <td>book thing george stimpson</td>\n",
              "      <td>vintage book thousand thing george stimpson fi...</td>\n",
              "      <td></td>\n",
              "      <td>book thing george stimpson vintage book thousa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27115</th>\n",
              "      <td>1358895140</td>\n",
              "      <td>vintage story sugar hawaii softcover book hawa...</td>\n",
              "      <td>story sugar hawaiipublished hawaiian sugar pla...</td>\n",
              "      <td>vintagehawaiisugarhistoryhawaiianfirst edition...</td>\n",
              "      <td>vintage story sugar hawaii softcover book hawa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27116</th>\n",
              "      <td>1366768240</td>\n",
              "      <td>francis king man rock vintage penguin book fir...</td>\n",
              "      <td>man rock seventh novel francis king hail beryl...</td>\n",
              "      <td>penguin book penguinbook lover gift classic bo...</td>\n",
              "      <td>francis king man rock vintage penguin book fir...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27117</th>\n",
              "      <td>1168372040</td>\n",
              "      <td>child abbey regina roche three volume one illu...</td>\n",
              "      <td>charm early victorian antique edition child ab...</td>\n",
              "      <td>child abbeyregina maria rocheregina rochevicto...</td>\n",
              "      <td>child abbey regina roche three volume one illu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27118</th>\n",
              "      <td>1157860460</td>\n",
              "      <td>eliot silas marner george eliot macmillan comp...</td>\n",
              "      <td>store pet smoke free environmentshipping optio...</td>\n",
              "      <td>silas marnerantique silas marnergeorge eliotma...</td>\n",
              "      <td>eliot silas marner george eliot macmillan comp...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>27119 rows Ã— 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1fbe7c9d-41e0-4f96-a50a-24fd038ff86a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1fbe7c9d-41e0-4f96-a50a-24fd038ff86a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1fbe7c9d-41e0-4f96-a50a-24fd038ff86a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#final.to_csv(r'/content/gdrive/MyDrive/Etsy_Data/final_testing_clean_data.csv', index=False)\n",
        "\n",
        "final = pd.read_csv('/content/gdrive/MyDrive/Etsy_Data/final_testing_clean_data.csv')"
      ],
      "metadata": {
        "id": "Mos1FmtO_oYO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = CountVectorizer(max_features=10000)\n",
        "\n",
        "batch_size = 20000\n",
        "num_batches = len(final) // batch_size + (len(final) % batch_size > 0)\n",
        "test_pred = []\n",
        "\n",
        "for i in range(num_batches):\n",
        "    start_idx = i * batch_size\n",
        "    end_idx = min(start_idx + batch_size, len(final))\n",
        "    Y = final['combine'][start_idx:end_idx]\n",
        "    Y = vectorizer.fit_transform(final['combine'])\n",
        "    test_pred_top = model_top.predict(Y)"
      ],
      "metadata": {
        "id": "GZgVIvVhrAWJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = CountVectorizer(max_features=66691)\n",
        "\n",
        "batch_size = 20000\n",
        "num_batches = len(final) // batch_size + (len(final) % batch_size > 0)\n",
        "test_pred = []\n",
        "\n",
        "for i in range(num_batches):\n",
        "    start_idx = i * batch_size\n",
        "    end_idx = min(start_idx + batch_size, len(final))\n",
        "    Y = final['combine'][start_idx:end_idx]\n",
        "    Y = vectorizer.fit_transform(final['combine'])\n",
        "    test_pred = model.predict(Y)"
      ],
      "metadata": {
        "id": "tPX7VwUaq96F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OzEl_lxfagUO"
      },
      "outputs": [],
      "source": [
        "vectorizer = CountVectorizer(max_features=66691)\n",
        "\n",
        "batch_size = 20000\n",
        "num_batches = len(final) // batch_size + (len(final) % batch_size > 0)\n",
        "test_pred = []\n",
        "\n",
        "for i in range(num_batches):\n",
        "    start_idx = i * batch_size\n",
        "    end_idx = min(start_idx + batch_size, len(final))\n",
        "    Y = final['combine'][start_idx:end_idx]\n",
        "    Y = vectorizer.fit_transform(final['combine'])\n",
        "    test_pred = model_color.predict(Y)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_pred_top = pd.DataFrame(test_pred_top)\n",
        "#test_pred = final['product_id'] + test_pred\n",
        "test_pred = pd.concat([test_pred_top,final['product_id']],axis=1)"
      ],
      "metadata": {
        "id": "2QO3oKT2fph6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pDDWPdxFBTq-"
      },
      "outputs": [],
      "source": [
        "test_pred.to_csv(r'/content/gdrive/MyDrive/Etsy_Data/top_category_prediction_22266982.csv',index=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_pred = pd.DataFrame(test_pred)\n",
        "#test_pred = final['product_id'] + test_pred\n",
        "test_pred = pd.concat([test_pred,final['product_id']],axis=1)"
      ],
      "metadata": {
        "id": "3LBb8VTtdr3v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_pred.to_csv(r'/content/gdrive/MyDrive/Etsy_Data/bottom_category_prediction_22266982.csv',index=False)"
      ],
      "metadata": {
        "id": "EuIBnRwD1WoH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_pred = pd.DataFrame(test_pred)\n",
        "#test_pred = final['product_id'] + test_pred\n",
        "test_pred = pd.concat([test_pred,final['product_id']],axis=1)\n",
        "test_pred.to_csv(r'/content/gdrive/MyDrive/Etsy_Data/color_category_prediction_22266982.csv',index=False)"
      ],
      "metadata": {
        "id": "7dGiL_nM1fCV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SrGzTInh2GUQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}