{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f067435",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "import glob\n",
    "import pyarrow.parquet as pq\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "import math\n",
    "import re\n",
    "import string\n",
    "import pyarrow as pa\n",
    "import os\n",
    "import math\n",
    "import seaborn as sb\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')\n",
    "#!unzip /content/gdrive/MyDrive/data.zip -d /content/gdrive/MyDrive/Etsy_Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c21806",
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting path and loading the paraquet file\n",
    "PATH = f\"Your Data Path\"\n",
    "p_f = f'{PATH}/parquet/train'\n",
    "test = pd.read_parquet(p_f,engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642398ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking all Columns in Data\n",
    "test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2810ed55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking all the information related to data\n",
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28943082",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping the columns which are not required\n",
    "test = test.drop(['type', 'room',\n",
    "       'craft_type', 'recipient', 'material', 'occasion', 'holiday',\n",
    "       'art_subject', 'style', 'shape', 'pattern'],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d856898c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Basic Cleaning of text data that is filling NA, removing special characters, links and standardising data\n",
    "test['title'] = test['title'].fillna(\"\")\n",
    "test['title'] = test['title'].apply(lambda x: x.lower() if pd.notna(x) else x)\n",
    "test['title'] = test['title'].str.replace(r'\\\\n','')\n",
    "test['title'] = test['title'].str.replace('[^A-Za-z\\s]','')\n",
    "test['title'] = test['title'].str.replace('\\d+','')\n",
    "test['title'] = test['title'].str.replace(r'http\\S+|www.\\S+', '')\n",
    "\n",
    "test['description'] = test['description'].fillna(\"\")\n",
    "test['description'] = test['description'].apply(lambda x: x.lower() if pd.notna(x) else x)\n",
    "test['description'] = test['description'].str.replace(r'\\\\n','')\n",
    "test['description'] = test['description'].str.replace('[^A-Za-z\\s]','')\n",
    "test['description'] = test['description'].str.replace('\\d+','')\n",
    "test['description'] = test['description'].str.replace(r'http\\S+|www.\\S+', '')\n",
    "\n",
    "test['tags'] = test['tags'].fillna(\"\")\n",
    "test['tags'] = test['tags'].apply(lambda x: x.lower() if pd.notna(x) else x)\n",
    "test['tags'] = test['tags'].str.replace(r'\\\\n','')\n",
    "test['tags'] = test['tags'].str.replace('[^A-Za-z\\s]','')\n",
    "test['tags'] = test['tags'].str.replace('\\d+','')\n",
    "test['tags'] = test['tags'].str.replace(r'http\\S+|www.\\S+', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31d89db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing stopwords\n",
    "nltk.download('stopwords')\n",
    "stop_words = stopwords.words('english')\n",
    "def remove_stop_words(text):\n",
    "    if pd.isna(text):\n",
    "        return ''\n",
    "    words = text.split()\n",
    "    filtered_words = [word for word in words if len(word) > 2 and word not in stop_words]\n",
    "    return ' '.join(filtered_words)\n",
    "\n",
    "test['title'] = test['title'].apply(remove_stop_words)\n",
    "test['description'] = test['description'].apply(remove_stop_words)\n",
    "test['tags'] = test['tags'].apply(remove_stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ae1e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lemmatising data \n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def wordnet_pos(tag):\n",
    "        if tag.startswith('J'):\n",
    "            return wordnet.ADJ\n",
    "        elif tag.startswith('R'):\n",
    "            return wordnet.ADV\n",
    "        elif tag.startswith('V'):\n",
    "            return wordnet.VERB\n",
    "        elif tag.startswith('N'):\n",
    "            return wordnet.NOUN\n",
    "        else:\n",
    "            return wordnet.NOUN\n",
    "\n",
    "def lemmatization_of_text(text):\n",
    "    words = word_tokenize(text)\n",
    "    pos_tags = nltk.pos_tag(words)\n",
    "    lemmatized_words = [lemmatizer.lemmatize(word, wordnet_pos(tag)) for word, tag in pos_tags]\n",
    "    lemmatized_text = ' '.join(lemmatized_words)\n",
    "    return lemmatized_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa883dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['description']=test['description'].apply(lemmatization_of_text)\n",
    "test['title']=test['title'].apply(lemmatization_of_text)\n",
    "test['tags']=test['tags'].apply(lemmatization_of_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2c3851",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combining all the columns and creating new one \n",
    "test['combine'] = test['title'] + ' ' + test['description'] + ' ' + test['tags']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08fbfb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predicting one variable at a time\n",
    "#Logistic regression for predicting Top Category variable\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score,accuracy_score\n",
    "\n",
    "#Batching the data since it is little heavy to run\n",
    "batch_size = 20000\n",
    "num_batches = len(test) // batch_size + (len(test) % batch_size > 0)\n",
    "model_top = LogisticRegression(max_iter=1000)\n",
    "\n",
    "vectorizer = CountVectorizer(max_features=10000)\n",
    "y_true_train = []\n",
    "y_pred_train = []\n",
    "y_true_val = []\n",
    "y_pred_val = []\n",
    "\n",
    "for i in range(num_batches):\n",
    "    start_idx = i * batch_size\n",
    "    end_idx = min(start_idx + batch_size, len(test))\n",
    "    X_text = test['combine'][start_idx:end_idx]\n",
    "    y = test['top_category_id'][start_idx:end_idx]\n",
    "\n",
    "    X = vectorizer.fit_transform(X_text)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    model_top.fit(X_train,y_train)\n",
    "\n",
    "    y_pred_train_batch = model_top.predict(X_train)\n",
    "    y_true_train.extend(y_train)\n",
    "    y_pred_train.extend(y_pred_train_batch)\n",
    "\n",
    "    y_pred_val_batch = model_top.predict(X_test)\n",
    "    y_true_val.extend(y_test)\n",
    "    y_pred_val.extend(y_pred_val_batch)\n",
    "\n",
    "    train_recall = recall_score(y_true_train, y_pred_train, average='weighted')\n",
    "    train_f1_score = f1_score(y_true_train, y_pred_train, average='weighted')\n",
    "    train_accuracy = accuracy_score(y_true_train, y_pred_train)\n",
    "\n",
    "    val_recall = recall_score(y_true_val, y_pred_val, average='weighted')\n",
    "    val_f1_score = f1_score(y_true_val, y_pred_val, average='weighted')\n",
    "    val_accuracy = accuracy_score(y_true_val, y_pred_val)\n",
    "\n",
    "print(\"Top Category - Recall: {:.4f}, F1 Score: {:.4f}, Accuracy: {:.4f}\".format(train_recall, train_f1_score, train_accuracy))\n",
    "print(\"Val Top Category - Recall: {:.4f}, F1 Score: {:.4f}, Accuracy: {:.4f}\".format(val_recall, val_f1_score, val_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf580cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predicting multiple varibleas at same time\n",
    "#Using Multi regressor for predicting multiple variables at same time\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, recall_score, accuracy_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define batch size and calculate the number of batches\n",
    "batch_size = 20000\n",
    "num_batches = len(test) // batch_size + (len(test) % batch_size > 0)\n",
    "\n",
    "# Initialize CountVectorizer\n",
    "vectorizer = CountVectorizer(max_features=10000)\n",
    "\n",
    "# Initialize progress bar\n",
    "pbar = tqdm(total=num_batches, desc=\"Training Progress\")\n",
    "\n",
    "# Initialize lists to store true and predicted values for top and bottom categories\n",
    "y_true_train_top = []\n",
    "y_pred_train_top = []\n",
    "y_true_val_top = []\n",
    "y_pred_val_top = []\n",
    "\n",
    "y_true_train_bottom = []\n",
    "y_pred_train_bottom = []\n",
    "y_true_val_bottom = []\n",
    "y_pred_val_bottom = []\n",
    "\n",
    "# Loop over batches\n",
    "for i in range(num_batches):\n",
    "    start_idx = i * batch_size\n",
    "    end_idx = min(start_idx + batch_size, len(test))\n",
    "    X_text = test['combine'][start_idx:end_idx]\n",
    "    y_top = test['top_category_id'][start_idx:end_idx]\n",
    "    y_bottom = test['bottom_category_id'][start_idx:end_idx]\n",
    "\n",
    "    X = vectorizer.fit_transform(X_text)\n",
    "    X_train, X_test, y_train_top, y_test_top, y_train_bottom, y_test_bottom = train_test_split(X, y_top, y_bottom, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Initialize logistic regression models\n",
    "    model_top = LogisticRegression(max_iter=1000)\n",
    "    model_bottom = LogisticRegression(max_iter=1000)\n",
    "\n",
    "    # Fit logistic regression models for top and bottom categories\n",
    "    model_top.fit(X_train, y_train_top)\n",
    "    model_bottom.fit(X_train, y_train_bottom)\n",
    "\n",
    "    # Predictions for top category\n",
    "    y_pred_train_top_batch = model_top.predict(X_train)\n",
    "    y_true_train_top.extend(y_train_top)\n",
    "    y_pred_train_top.extend(y_pred_train_top_batch)\n",
    "\n",
    "    y_pred_val_top_batch = model_top.predict(X_test)\n",
    "    y_true_val_top.extend(y_test_top)\n",
    "    y_pred_val_top.extend(y_pred_val_top_batch)\n",
    "\n",
    "    # Predictions for bottom category\n",
    "    y_pred_train_bottom_batch = model_bottom.predict(X_train)\n",
    "    y_true_train_bottom.extend(y_train_bottom)\n",
    "    y_pred_train_bottom.extend(y_pred_train_bottom_batch)\n",
    "\n",
    "    y_pred_val_bottom_batch = model_bottom.predict(X_test)\n",
    "    y_true_val_bottom.extend(y_test_bottom)\n",
    "    y_pred_val_bottom.extend(y_pred_val_bottom_batch)\n",
    "\n",
    "    # Update progress bar\n",
    "    pbar.update(1)\n",
    "    print(\"Progress bar is updating at this line of code.\")\n",
    "\n",
    "# Close the progress bar\n",
    "pbar.close()\n",
    "\n",
    "# Calculate evaluation metrics for top category\n",
    "train_recall_top = recall_score(y_true_train_top, y_pred_train_top, average='weighted')\n",
    "train_f1_score_top = f1_score(y_true_train_top, y_pred_train_top, average='weighted')\n",
    "train_accuracy_top = accuracy_score(y_true_train_top, y_pred_train_top)\n",
    "\n",
    "val_recall_top = recall_score(y_true_val_top, y_pred_val_top, average='weighted')\n",
    "val_f1_score_top = f1_score(y_true_val_top, y_pred_val_top, average='weighted')\n",
    "val_accuracy_top = accuracy_score(y_true_val_top, y_pred_val_top)\n",
    "\n",
    "# Calculate evaluation metrics for bottom category\n",
    "train_recall_bottom = recall_score(y_true_train_bottom, y_pred_train_bottom, average='weighted')\n",
    "train_f1_score_bottom = f1_score(y_true_train_bottom, y_pred_train_bottom, average='weighted')\n",
    "train_accuracy_bottom = accuracy_score(y_true_train_bottom, y_pred_train_bottom)\n",
    "\n",
    "val_recall_bottom = recall_score(y_true_val_bottom, y_pred_val_bottom, average='weighted')\n",
    "val_f1_score_bottom = f1_score(y_true_val_bottom, y_pred_val_bottom, average='weighted')\n",
    "val_accuracy_bottom = accuracy_score(y_true_val_bottom, y_pred_val_bottom)\n",
    "\n",
    "# Print evaluation metrics for top category\n",
    "print(\"Top Category - Train Recall: {:.4f}, F1 Score: {:.4f}, Accuracy: {:.4f}\".format(train_recall_top, train_f1_score_top, train_accuracy_top))\n",
    "print(\"Top Category - Val Recall: {:.4f}, F1 Score: {:.4f}, Accuracy: {:.4f}\".format(val_recall_top, val_f1_score_top, val_accuracy_top))\n",
    "\n",
    "# Print evaluation metrics for bottom category\n",
    "print(\"Bottom Category - Train Recall: {:.4f}, F1 Score: {:.4f}, Accuracy: {:.4f}\".format(train_recall_bottom, train_f1_score_bottom, train_accuracy_bottom))\n",
    "print(\"Bottom Category - Val Recall: {:.4f}, F1 Score: {:.4f}, Accuracy: {:.4f}\".format(val_recall_bottom, val_f1_score_bottom, val_accuracy_bottom))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc381dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385f5f34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7bc78a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5922b34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f2c0e93",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
